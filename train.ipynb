{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "1j0oEKPKW-B-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nOMwqygkXxAy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82f59a02-160c-4df4-faec-d87e4627a6cf"
      },
      "cell_type": "code",
      "source": [
        "cd train_data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/train_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K-UMgBJ-X1j9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "c3266fef-f472-4a03-c953-777fdb0fd765"
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/apple.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/pineapple.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/grapes.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/banana.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/bird.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/book.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/circle.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/candle.npy\n",
        "!wget https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cloud.npy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Redirecting output to ‘wget-log’.\n",
            "\n",
            "Redirecting output to ‘wget-log.1’.\n",
            "\n",
            "Redirecting output to ‘wget-log.2’.\n",
            "\n",
            "Redirecting output to ‘wget-log.3’.\n",
            "\n",
            "Redirecting output to ‘wget-log.4’.\n",
            "\n",
            "Redirecting output to ‘wget-log.5’.\n",
            "\n",
            "Redirecting output to ‘wget-log.6’.\n",
            "\n",
            "Redirecting output to ‘wget-log.7’.\n",
            "\n",
            "Redirecting output to ‘wget-log.8’.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sZbrlOagYgzu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "784a6861-70af-4b60-a6f9-c68800ed531b"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple.npy   book.npy\tcloud.npy      wget-log    wget-log.3  wget-log.6\n",
            "banana.npy  candle.npy\tgrapes.npy     wget-log.1  wget-log.4  wget-log.7\n",
            "bird.npy    circle.npy\tpineapple.npy  wget-log.2  wget-log.5  wget-log.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dKYBOhPyYtvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e9fa3a3e-76e7-4664-c812-f8be97653715"
      },
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qlLaOf7jc1ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "ce08ba28-28eb-44d9-8097-162918edc101"
      },
      "cell_type": "code",
      "source": [
        "!pip install tflearn"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tflearn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/ec/e9ce1b52e71f6dff3bd944f020cef7140779e783ab27512ea7c7275ddee5/tflearn-0.3.2.tar.gz (98kB)\n",
            "\u001b[K    100% |████████████████████████████████| 102kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tflearn) (1.11.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from tflearn) (4.0.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->tflearn) (0.46)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Running setup.py bdist_wheel for tflearn ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d0/f6/69/0ef3ee395aac2e5d15d89efd29a9a216f3c27767b43b72c006\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z8Q1Fs-XYwnr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "import numpy as np\n",
        "from os import listdir\n",
        "from PIL import Image\n",
        "import tflearn\n",
        "from tflearn.layers import dropout,conv_2d,max_pool_2d\n",
        "from tflearn.layers.core import input_data, fully_connected,flatten\n",
        "from tflearn.layers.estimator import regression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MlUyITRucwSG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "34998b87-d59e-455c-f951-0fc4f7cd566a"
      },
      "cell_type": "code",
      "source": [
        "no_classes = 9\n",
        "\n",
        "# number of samples to take in each class\n",
        "N = 5000\n",
        "\n",
        "# some other constants\n",
        "N_EPOCHS = 10\n",
        "\n",
        "# data files in the \n",
        "files = [i for i in listdir(\"train_data/\") if \"npy\" in i]\n",
        "print(files)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bird.npy', 'grapes.npy', 'circle.npy', 'book.npy', 'candle.npy', 'banana.npy', 'apple.npy', 'cloud.npy', 'pineapple.npy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pf53iim6gQOr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load(dir, reshaped, files):\n",
        "    \"Load .npy or .npz files from disk and return them as numpy arrays. \\\n",
        "    Takes in a list of filenames and returns a list of numpy arrays.\"\n",
        "\n",
        "    data = []\n",
        "    for file in files:\n",
        "        f = np.load(dir + file)\n",
        "        if reshaped:\n",
        "            new_f = []\n",
        "            for i in range(len(f)):\n",
        "                x = np.reshape(f[i], (28, 28))\n",
        "                x = np.expand_dims(x, axis=0)\n",
        "                x = np.reshape(f[i], (28, 28, 1))\n",
        "                new_f.append(x)\n",
        "            f = new_f\n",
        "        data.append(f)\n",
        "    return data\n",
        "\n",
        "\n",
        "def normalize(data):\n",
        "    \"Takes a list or a list of lists and returns its normalized form\"\n",
        "\n",
        "    return np.interp(data, [0, 255], [-1, 1])\n",
        "\n",
        "\n",
        "def denormalize(data):\n",
        "    \"Takes a list or a list of lists and returns its denormalized form\"\n",
        "\n",
        "    return np.interp(data, [-1, 1], [0, 255])\n",
        "\n",
        "\n",
        "def visualize(array):\n",
        "    \"Visulaze a 2D array as an Image\"\n",
        "    array = np.reshape(array, (28,28))\n",
        "    img = Image.fromarray(array)\n",
        "    return img\n",
        "\n",
        "\n",
        "def set_limit(arrays, n):\n",
        "    \"Limit elements from each array up to n elements and return a single list\"\n",
        "    new = []\n",
        "    for array in arrays:\n",
        "        i = 0\n",
        "        for item in array:\n",
        "            if i == n:\n",
        "                break\n",
        "            new.append(item)\n",
        "            i += 1\n",
        "    return new\n",
        "\n",
        "\n",
        "def make_labels(N1, N2):\n",
        "    \"make labels from 0 to N1, each repeated N2 times\"\n",
        "    labels = []\n",
        "    for i in range(N1):\n",
        "        labels += [i] * N2\n",
        "    return labels\n",
        "  \n",
        "  \n",
        "def get_one_hot(targets, nb_classes):\n",
        "    \"one hot encoding\"\n",
        "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "    return res.reshape(list(targets.shape)+[nb_classes])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DnFZpeOAgXJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#second argument is True for reshaping the image to a 28x28 form. A conv net expects this format.\n",
        "data = load(\"train_data/\", True, files)\n",
        " \n",
        "\n",
        "# limit no of samples in each class to N\n",
        "data = set_limit(data, N)\n",
        "\n",
        "# normalize the values\n",
        "data = list(map(normalize, data))\n",
        "\n",
        "# define the labels\n",
        "labels = make_labels(no_classes, N)\n",
        "labels = get_one_hot(np.array(labels),no_classes)\n",
        "# print(data[10],labels[10])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NFUBRhJDkdyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a61cd031-de2d-4f86-8a0a-8420dcdbf22c"
      },
      "cell_type": "code",
      "source": [
        "model = input_data((28,28,1),name=\"input\")\n",
        "model = conv_2d(model,32,(3,3),activation='relu')\n",
        "model = conv_2d(model,64,(3,3),activation='relu')\n",
        "model = max_pool_2d(model,(2,2))\n",
        "model = dropout(model,0.25)\n",
        "model = flatten(model)\n",
        "model = fully_connected(model,128,activation='relu')\n",
        "model = dropout(model,0.5)\n",
        "model = fully_connected(model,no_classes,activation='softmax')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tflearn/initializations.py:119: UniformUnitScaling.__init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5XM9m1EolAxV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "d4956667-fdee-4252-b4d3-79af77688ac3"
      },
      "cell_type": "code",
      "source": [
        "model = regression(model, optimizer='adam', learning_rate=0.001,\n",
        "                         loss='categorical_crossentropy', name='target')\n",
        "# Training\n",
        "model = tflearn.DNN(model, tensorboard_verbose=3)\n",
        "model.load('doodle_classifier.tflearn')\n",
        "model.fit({'input': data}, {'target': labels}, n_epoch=N_EPOCHS,batch_size=32,\n",
        "              validation_set=0.3, show_metric=True, run_id='doodle_classifier_1.0')\n",
        "model.save('doodle_classifier_1.0.tflearn')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Step: 19699  | total loss: \u001b[1m\u001b[32m0.30196\u001b[0m\u001b[0m | time: 159.684s\n",
            "| Adam | epoch: 010 | loss: 0.30196 - acc: 0.9420 -- iter: 31488/31499\n",
            "Training Step: 19700  | total loss: \u001b[1m\u001b[32m0.31970\u001b[0m\u001b[0m | time: 162.531s\n",
            "| Adam | epoch: 010 | loss: 0.31970 - acc: 0.9353 | val_loss: 0.16561 - val_acc: 0.9493 -- iter: 31499/31499\n",
            "--\n",
            "INFO:tensorflow:/content/doodle_classifier_1.0.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cTzTEYcq08TE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c62c7266-ac26-454c-a163-abe1b0ab065f"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint\n",
            "doodle_classifier_1.0.tflearn.data-00000-of-00001\n",
            "doodle_classifier_1.0.tflearn.index\n",
            "doodle_classifier_1.0.tflearn.meta\n",
            "doodle_classifier.tflearn.data-00000-of-00001\n",
            "doodle_classifier.tflearn.index\n",
            "doodle_classifier.tflearn.meta\n",
            "sample_data\n",
            "train_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ezobww2g1duk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('doodle_classifier_1.0.tflearn.data-00000-of-00001') \n",
        "files.download('doodle_classifier_1.0.tflearn.meta') \n",
        "files.download('doodle_classifier_1.0\n",
        "               .tflearn.index') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}